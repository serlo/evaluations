{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "featured-input",
   "metadata": {},
   "source": [
    "# Aktuelle Limitierungen:\n",
    "\n",
    "* Inhalte, die mehreren Fächern zugeordnet worden sind, zählen nur zu einem Fach\n",
    "* Es werden nur Bearbeitungen gezählt\n",
    "* Folgeevents einer Bearbeitung werden nicht zusammengefasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "display(Markdown(f\"### Letztes Update: {date.today()}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    \"mysql+mysqlconnector://root:secret@localhost:3306/serlo?charset=latin1\"\n",
    ")\n",
    "\n",
    "connection = engine.raw_connection()\n",
    "\n",
    "def cached(func):\n",
    "    cache = dict()\n",
    "    \n",
    "    def return_func(arg):\n",
    "        if (arg in cache):\n",
    "            return cache[arg]\n",
    "        else:\n",
    "            result = func(arg)\n",
    "            cache[arg] = result\n",
    "            return result\n",
    "    \n",
    "    return return_func\n",
    "\n",
    "def query(sql):\n",
    "    c = connection.cursor()\n",
    "    c.execute(sql)\n",
    "    \n",
    "    return c.fetchall()\n",
    "\n",
    "def querySingleton(sql):\n",
    "    return [ x[0] for x in query(sql) ]\n",
    "\n",
    "@cached\n",
    "def getParent(termId):\n",
    "    return querySingleton(\"\"\"\n",
    "        select parent_id from term_taxonomy where id = %s;\n",
    "    \"\"\" % termId)[0]\n",
    "\n",
    "def getTermName(termId):\n",
    "    return querySingleton(\"\"\"\n",
    "        select term.name from term_taxonomy\n",
    "        join term on term.id = term_taxonomy.term_id\n",
    "        where term_taxonomy.id = %s;\n",
    "    \"\"\" % termId)[0]\n",
    "\n",
    "@cached\n",
    "def getSubject(termId):\n",
    "    if int(termId) in [79733, 81317, 20852, 87814, 87827, 85477, 87860, 75049, 76750, 87496, 75678, 91252, 91253]:\n",
    "        return \"Prüfungsbereich Mathematik\"\n",
    "    if int(termId) in [106082]:\n",
    "        return getTermName(termId)\n",
    "    \n",
    "    parent = getParent(termId)\n",
    "    grandparent = getParent(parent)\n",
    "    \n",
    "    if (parent == 106081):\n",
    "        return getTermName(termId)\n",
    "    \n",
    "    return getSubject(parent) if grandparent != None else getTermName(termId)\n",
    "\n",
    "@cached\n",
    "def getSubjectFromUuid(uuid):\n",
    "    taxonomyTerms = querySingleton(f\"\"\"\n",
    "        select term_taxonomy_id from term_taxonomy_entity\n",
    "        where term_taxonomy_entity.entity_id  = {uuid};\n",
    "    \"\"\")\n",
    "    \n",
    "    if len(taxonomyTerms) > 0:\n",
    "        return getSubject(taxonomyTerms[0])\n",
    "\n",
    "    parents = querySingleton(f\"\"\"\n",
    "        select parent_id from entity_link\n",
    "        where entity_link.child_id  = {uuid};\n",
    "    \"\"\")\n",
    "    \n",
    "    if len(parents) > 0:\n",
    "        return getSubjectFromUuid(parents[0])\n",
    "    \n",
    "    return None\n",
    "\n",
    "#display(getSubjectFromUuid(127338))\n",
    "#display(getSubjectFromUuid(63496))\n",
    "#display(getSubjectFromUuid(1))\n",
    "#display(getSubjectFromUuid(170741))\n",
    "#display(getSubjectFromUuid(167497))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-exhibit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dumps(querySingleton(\"\"\"\n",
    "select distinct(entity_link.parent_id ) from event_log join entity_link on entity_link.child_id = event_log.uuid_id where event_log.event_id = 4 and event_log.date > Date(\"2020-02-01\");\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_event_log():\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        select event_log.id, event_log.actor_id, event_log.date, user.username, event_parameter_uuid.uuid_id from event_log\n",
    "        join user on user.id = event_log.actor_id\n",
    "        join event_parameter on event_parameter.log_id = event_log.id\n",
    "        join event_parameter_uuid on event_parameter_uuid.event_parameter_id = event_parameter.id\n",
    "        where event_log.event_id = 5\n",
    "        and year(event_log.date) > 2018\n",
    "        and user.username != \"Legacy\"\n",
    "    \"\"\", con=engine)\n",
    "    df.set_index(\"id\", inplace=True)\n",
    "    df.rename(columns={\"uuid_id\": \"uuid\"}, inplace=True)\n",
    "    df[\"subject\"] = df[\"uuid\"].map(getSubjectFromUuid)\n",
    "    return df\n",
    "\n",
    "event_log = read_event_log()\n",
    "event_log.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12de6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Rate pro Fach\n",
    "\n",
    "def calc_activation_rates(days, edits, baseline):\n",
    "    subject_list = list(filter(None, list(event_log['subject'].unique())))\n",
    "    rates_df = pd.DataFrame(columns = ['subject', 'activation_rate', 'loss_rate'])\n",
    "\n",
    "    for subject in subject_list:\n",
    "        between_df = pd.DataFrame()\n",
    "        activation_rate = int()\n",
    "        loss_rate = int()\n",
    "        for month in range(0,2):\n",
    "\n",
    "            lower_date = pd.Timestamp.today() - pd.Timedelta(days = days + month*30)\n",
    "            upper_date = pd.Timestamp.today() - pd.Timedelta(days = month*30)\n",
    "            df1 = pd.DataFrame()\n",
    "            df2 = pd.DataFrame()\n",
    "            df3 = pd.DataFrame()\n",
    "            df4 = pd.DataFrame()\n",
    "            df5 = pd.DataFrame()\n",
    "\n",
    "            df1 = event_log[lower_date < event_log['date']] \n",
    "            df2 = df1[df1['date'] < upper_date]\n",
    "            df3 = df2[df2['subject'] == subject]\n",
    "            df4 = df3.groupby(by = ['actor_id', 'username', 'subject'], as_index = False).count()\n",
    "            #Delete all authors under baseline\n",
    "            df5 = df4[df4['uuid']>= baseline]\n",
    "            df5['isActive'] = df5['uuid'].apply(lambda x: 1 if x >= edits else 0)\n",
    "\n",
    "            if between_df.empty:\n",
    "                between_df = df5\n",
    "            else:\n",
    "                between_df = pd.merge(between_df, df5[['actor_id', 'isActive']], on=[\"actor_id\"])\n",
    "\n",
    "        if not between_df.empty and 'isActive_x' in between_df.columns and 'isActive_y' in between_df.columns:\n",
    "            between_df['change'] = between_df['isActive_x'] - between_df['isActive_y']\n",
    "            activation_rate = between_df['change'][between_df['change']>0].sum() / len(between_df)\n",
    "            loss_rate = between_df['change'][between_df['change']<0].sum() / len(between_df)\n",
    "        else:\n",
    "            continue\n",
    "        append_df = pd.DataFrame([[subject, round(activation_rate,2), round(loss_rate, 2)]], columns=['subject', 'activation_rate', 'loss_rate'])\n",
    "        rates_df = pd.concat([rates_df, append_df], ignore_index=True)\n",
    "    return rates_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Aktivierungsrate pro Fach: Nicht aktive zu aktiven AutorInnen\"))\n",
    "display(Markdown(f\"Edits: 10, im Zeitraum: Letzte 90 Tage\"))\n",
    "calc_activation_rates(days=90, edits=10, baseline = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Aktivierungsrate pro Fach: Aktive zu mittelaktiven Autorinnen\"))\n",
    "display(Markdown(f\"Edits: von 10 auf 50, im Zeitraum: Letzte 90 Tage\"))\n",
    "calc_activation_rates(days=90, edits=50, baseline=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002862f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Rate über alle Fächer hinweg\n",
    "\n",
    "def calc_act_rates_wo_subj(days, edits, baseline):\n",
    "    result_df = pd.DataFrame()\n",
    "    activation_rate = 0\n",
    "    loss_rate = 0\n",
    "    \n",
    "    for month in range(0,2):\n",
    "\n",
    "        lower_date = pd.Timestamp.today() - pd.Timedelta(days = days + month*30)\n",
    "        upper_date = pd.Timestamp.today() - pd.Timedelta(days = month*30)\n",
    "        df1 = pd.DataFrame()\n",
    "        df2 = pd.DataFrame()\n",
    "        df3 = pd.DataFrame()\n",
    "\n",
    "        df1 = event_log[lower_date < event_log['date']] \n",
    "        df2 = df1[df1['date'] < upper_date]\n",
    "        df3 = df2.groupby(by = ['actor_id', 'username'], as_index = False).count()\n",
    "        #Delete all authors under baseline\n",
    "        df4 = df3[df3['uuid']>= baseline]\n",
    "        df4['isActive'] = df4['uuid'].apply(lambda x: 1 if x >= edits else 0)\n",
    "\n",
    "        if result_df.empty:\n",
    "            result_df = df4\n",
    "        else:\n",
    "            result_df = pd.merge(result_df, df4[['actor_id', 'isActive']], on=[\"actor_id\"])\n",
    "\n",
    "    if not result_df.empty: #and 'isActive_x' in between_df.columns and 'isActive_y' in between_df.columns:\n",
    "        result_df['change'] = result_df['isActive_x'] - result_df['isActive_y']\n",
    "        activation_rate = result_df['change'][result_df['change']>0].sum() / len(result_df)\n",
    "        loss_rate = result_df['change'][result_df['change']<0].sum() / len(result_df)\n",
    "        \n",
    "    return activation_rate, loss_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Aktivierungsrate Fächerübergreifend: Nicht aktive zu aktiven Autorinnen\"))\n",
    "display(Markdown(f\"Edits: 10, im Zeitraum: Letzte 90 Tage\"))\n",
    "display(Markdown(f\"Aktivierungsrate: {round(calc_act_rates_wo_subj(days=90, edits=10, baseline=0)[0], 2)}\"))\n",
    "display(Markdown(f\"Verlustrate: {round(calc_act_rates_wo_subj(days=90, edits=10, baseline=0)[1], 2)}\"))\n",
    "display(Markdown(f\"Bitte beachte, dass diese Zahl nicht analog zur Aktivierungs/Verlustrate pro Fach ist, da AutorInnen in verschiedenen Fächern aktiv sein können\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Aktivierungsrate Fächerübergreifend: von aktiven zu mittelaktiven AutorInnen\"))\n",
    "display(Markdown(f\"Edits: von 10 auf 50, im Zeitraum: Letzte 90 Tage\"))\n",
    "display(Markdown(f\"Aktivierungsrate: {round(calc_act_rates_wo_subj(days=90, edits=50, baseline=10)[0], 2)}\"))\n",
    "display(Markdown(f\"Verlustrate: {round(calc_act_rates_wo_subj(days=90, edits=50, baseline=10)[1], 2)}\"))\n",
    "display(Markdown(f\"Bitte beachte, dass diese Zahl nicht analog zur Aktivierungs/Verlustrate pro Fach ist, da AutorInnen in verschiedenen Fächern aktiv sein können\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-tsunami",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(subject=None, lower=10, time_interval=90):\n",
    "    df = event_log.copy()\n",
    "    \n",
    "    if subject:\n",
    "        df = df[df[\"subject\"] == subject]\n",
    "        if len(df) == 0:\n",
    "            return\n",
    "        \n",
    "    edits_per_day = compute_edits_per_day_per_user(df)\n",
    "    df = edits_per_day.rolling(time_interval, min_periods=time_interval).sum()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    display(Markdown(f\"### Plot Anzahl Autor:innen mit Edits >= {lower}\"))\n",
    "    df.apply(lambda x: x.map(lambda y: y >= lower).sum(), axis=1).plot(figsize=(10,10))\n",
    "    plt.show()\n",
    "    \n",
    "    df2 = pd.DataFrame({\n",
    "        \"edits\": df.loc[df.index[-1]],\n",
    "        \"edits_before\": df.loc[df.index[-1-time_interval]],\n",
    "    })\n",
    "    \n",
    "    count = (df2[\"edits\"] >= lower).sum()\n",
    "    \n",
    "    display(Markdown(f\"Anzahl Autor:innen mit Edits >= {lower}: {count}\"))\n",
    "    \n",
    "    display(Markdown(f\"### Autor:innen mit aktuellen Edits >= {lower}\"))\n",
    "    d = df2[df2[\"edits\"] >= lower][[\"edits\"]]\n",
    "    d.sort_values(\"edits\", inplace=True, ascending=False)\n",
    "    display(d)\n",
    "    \n",
    "    display(Markdown(f\"### Verlorene Autor:innen mit aktuellen Edits < {lower} und vorher Edits >= {lower}\"))\n",
    "    d = df2[(df2[\"edits\"] < lower) & (df2[\"edits_before\"] >= lower)][[\"edits\"]]\n",
    "    d.sort_values(\"edits\", inplace=True, ascending=False)\n",
    "    display(d)\n",
    "    \n",
    "    display(Markdown(f\"### Neue Autor:innen (Personen, die in den letzten {time_interval} Tagen dazugekommen sind)\"))\n",
    "    df3 = edits_per_day.cumsum()\n",
    "    df3 = pd.DataFrame({\n",
    "        \"edits\": df3.loc[df.index[-1]],\n",
    "        \"edits_before\": df3.loc[df.index[-1-time_interval]],\n",
    "    })\n",
    "    d = df3[(df3[\"edits\"] > 0) & (df3[\"edits_before\"] == 0)][[\"edits\"]]\n",
    "    d.sort_values(\"edits\", inplace=True, ascending=False)\n",
    "    display(d)\n",
    "    \n",
    "    display(Markdown(f\"### Neue Autor:innen (Personen, die in den letzten {time_interval} Tagen dazugekommen sind) + Edits < {lower}\"))\n",
    "    d = df3[(df3[\"edits\"] < lower) & (df3[\"edits\"] > 0) & (df3[\"edits_before\"] == 0)][[\"edits\"]]\n",
    "    d.sort_values(\"edits\", inplace=True, ascending=False)\n",
    "    display(d)\n",
    "\n",
    "def compute_edits_per_day_per_user(df, since=4*365.25):\n",
    "    current_date = df[\"date\"].max()     # This should probably be set to today!\n",
    "    df = df[df[\"date\"] > current_date - pd.Timedelta(days=since)]\n",
    "    \n",
    "    def user_df(username):\n",
    "        #display(df.head())\n",
    "        u = df[df[\"username\"] == username].copy()\n",
    "        u.set_index(\"date\", inplace=True)\n",
    "        u = u.resample(\"D\").count()[[\"actor_id\"]]\n",
    "        u.rename(columns={\"actor_id\": username}, inplace=True)\n",
    "        return u\n",
    "    \n",
    "    df = pd.concat([user_df(u) for u in df[\"username\"].unique()], axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-apache",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-microphone",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(lower=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-optimization",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(lower=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1c50c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(lower=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log[\"subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-divide",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for subject in [\"Mathe\", \"Chemie\", \"Physik\",\n",
    "                  \"Nachhaltigkeit\", \"Biologie\", \"Sandkasten\", \"Prüfungsbereich Mathematik\",\n",
    "               \"Geographie\", \"Geschichte\", \"Community\", \"Informatik\", \"Englisch\"]:\n",
    "    \n",
    "    display(Markdown(f\"## Fach: {subject}\"))\n",
    "    show(subject=subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-nebraska",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_no_authors():\n",
    "    def current_no_authors(d):\n",
    "        return d[pd.Timestamp.today() - d[\"date\"] < pd.Timedelta(\"90 days\")][\"username\"].nunique()\n",
    "    \n",
    "    def last_year_no_authors(d):\n",
    "        return d[\n",
    "            (d[\"date\"] < pd.Timestamp.today() - pd.Timedelta(\"365 days\")) &\n",
    "            (d[\"date\"] > pd.Timestamp.today() - pd.Timedelta(\"455 days\"))\n",
    "        ][\"username\"].nunique()\n",
    "    \n",
    "    return event_log.groupby(\"subject\").apply(lambda d: pd.Series({\n",
    "        \"current no authors\": current_no_authors(d),\n",
    "        \"last year no authors\": last_year_no_authors(d)\n",
    "    }))\n",
    "\n",
    "show_no_authors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
